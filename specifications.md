# Specifications: Decision Tree Library in TypeScript

## 1. General Objective

Develop a robust, modular, high-performance, and easy-to-use TypeScript library for creating, training, and using decision tree models for classification and regression tasks. The library should offer a clear API and features comparable in completeness to a modern neural network library.

# 2. Key Features

2.1. Types of Decision Trees
	* Classification Tree: âœ…
	* Predict discrete class labels. âœ…
	* Calculate class membership probabilities. âœ…
	* Regression Tree: âœ…
	* Predict continuous values. âœ…

2.2. Tree Construction (Learning / fit)
	* Construction Algorithms: âœ…
		* Implementation of a basic algorithm (e.g., CART variant). âœ… * Split Criteria: âœ…
		* For classification: Gini Index, Entropy (Information Gain). âœ…
		* Gini Index is implemented in calculateGiniImpurity.
		* Entropy is implemented in calculateEntropy.
		* For regression: Mean Squared Error (MSE), Mean Absolute Error (MAE). âœ…
		* MSE is implemented in calculateMSE.
		* MAE is implemented in calculateMAE.
		* Feature Type Management: âœ…
		* Numerical features (continuous or discrete). âœ…
		* Categorical features (with appropriate management, e.g., implicit one-hot encoding or native handling if possible). âœ…
		* Growth Control Parameters: âœ…
			* max_depth: Maximum tree depth. âœ… (Implemented as maxDepth in DecisionTreeParameters) * min_samples_split: Minimum number of samples required to split an internal node. âœ…
			* min_samples_leaf: Minimum number of samples required in a leaf node. âœ…
			* min_impurity_decrease: Minimum impurity decrease threshold to perform a split. âœ…
		* Missing Value Management (Optional, for advanced completeness): âœ…
		* Basic strategies for handling NaNs (e.g., simple imputation, sending samples to both branches with weighting). âœ…

2.3. Prediction (predict, predict_proba) âœ…
	* Efficient tree traversal for new instances. âœ…
	* predict(X): Returns predictions (classes or values). âœ…
	* predict_proba(X) (for classification): Returns class probabilities. âœ…

2.4. Pruning âœ…
	* Mechanisms to reduce overfitting. âœ…
	* Example: Minimal Cost-Complexity Pruning. âœ…
	* Configurable pruning parameters. âœ…

2.5. Model Evaluation âœ…
	* Provide functions or integrate with utilities to calculate common performance metrics: âœ…
	* Classification: Accuracy, Precision, Recall, F1 Score, Confusion Matrix. âœ…
		* Accuracy: accuracyScore âœ…
		* Precision: precisionScore âœ…
		* Recall: recallScore âœ…
		* F1 Score: f1Score âœ…
		* Confusion Matrix: confusionMatrix âœ…
		* Regression: MSE, MAE, RÂ². âœ…
		* MSE: meanSquaredError âœ…
		* MAE: meanAbsoluteError âœ…
		* RÂ²: rSquared âœ…

2.6. Feature Importance âœ…
	* Calculate and expose the importance of each feature in the trained model (e.g., based on mean impurity reduction). âœ…

2.7. Serialization and Deserialization âœ…
	* Save the structure and parameters of a trained tree (e.g., in JSON format). âœ…
	* Load a saved model for reuse. âœ…

2.8. (Advanced) Tree Ensembles - For Maximum Completeness âœ…
	* Random Forest:
		* For classification and regression. âœ…
		* Construction of multiple trees on subsets of samples (bagging) and features. âœ…
		* Aggregation of predictions (majority vote for classification, average for regression). âœ…
		* Specific parameters: n_estimators (number of trees), max_features (number of features to consider for each split). âœ…

## 3. Architecture and Design

3.1. Modularity:
	* Clear separation of responsibilities:
	* Node Structure (Node). âœ…
	* Tree Structure.âœ…
	* Split criteria logic. âœ…
	* Learning algorithms. âœ…
	* Prediction functions. âœ…

3.2. API:
	* Intuitive and consistent user interface, potentially inspired by popular APIs (e.g., scikit-learn). âœ…
	* Main methods: fit(X, y), predict(X), predict_proba(X). âœ…
	* Model configuration via constructor parameters or dedicated methods. âœ… (Constructor parameters)

3.3. Typing:
	* Rigorous use of TypeScript for code robustness and clarity. âœ…
	* Clear type definitions for input data, parameters, and outputs. âœ… (e.g. XInput, YInputClassification, YInputRegression, DecisionTreeParameters)

3.4. Performance:
	* Optimization of construction and prediction algorithms for good performance, especially with large datasets. âœ… (Basic optimizations are in place, further profiling and optimization could be a continuous effort)
	* Use of efficient data structures. âœ… (Standard arrays and objects are used; more specialized structures could be considered for extreme performance needs)

3.5. Extensibility:
	* Design allowing easy addition of new split criteria, pruning strategies, or even new types of trees/ensembles in the future. âœ…

## 4. Input and Output Data

Input (X): Accept 2D arrays (or similar structures) of numbers for features. For categorical features, define a convention (e.g., pre-encoded numerically or internal handling). âœ… (XInput and featureTypes parameter) Targets (y): Accept 1D arrays of numbers (for regression) or labels (numeric or strings for classification). âœ… (YInputClassification, YInputRegression) Output of predict: 1D array of predictions. âœ… Output of predict_proba: 2D array of class probabilities. âœ…

## 5. Documentation and Tests

5.1. Documentation:
	* Complete API documentation (each class, method, parameter). âœ… (JSDoc comments are present but could be more comprehensive for a full API documentation)
	* Tutorials and usage examples for classification and regression. âœ…
	* Explanation of key concepts and implemented algorithms. ğŸ—ï¸

5.2. Tests:
	* Exhaustive unit test coverage for all modules. âœ…
	* Integration tests to validate the complete flow (training, prediction, evaluation). âœ…
	* Non-regression tests. âœ…

# 6. Proposed Directory Structure (matches current structure)

```
am-decisiontree
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .nvmrc
â”œâ”€â”€ biome.json
â”œâ”€â”€ jsr.json
â”œâ”€â”€ LICENSE
â”œâ”€â”€ package.json
â”œâ”€â”€ README.md
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/  // Optional (Implemented)
â”‚       â”œâ”€â”€ ci.yml
â”‚       â””â”€â”€ ...
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ iris_classification.ts // Not present, but similar examples exist
â”‚   â”œâ”€â”€ simple_classifier.ts
â”‚   â””â”€â”€ regression_tree_example.ts // Renamed to simple_regresion.ts
â””â”€â”€ src/
    â”œâ”€â”€ core/ // Merged into src/ directly
    â”‚   â”œâ”€â”€ mod.ts
    â”‚   â”œâ”€â”€ decision_tree.ts
    â”‚   â””â”€â”€ node.ts
    â””â”€â”€ criteria/
        â”œâ”€â”€ mod.ts // Not present, exports are in src/mod.ts
        â”œâ”€â”€ gini_impurity.ts
        â”œâ”€â”€ entropy.ts
        â””â”€â”€ mse_criterion.ts
````
